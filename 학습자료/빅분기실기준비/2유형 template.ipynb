{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅데이터 분석기사 2유형 템플릿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder          # 인코딩(분류형)\n",
    "from sklearn.preprocessing import StandardScaler        # 인코딩(수치형)\n",
    "from sklearn.model_selection import train_test_split    # 데이터 분할\n",
    "\n",
    "# 분류모델\n",
    "from sklearn.ensemble import RandomForestClassifier     # 분류모델, 랜덤포레스트\n",
    "from xgboost import XGBClassifier                       # 분류모델, XGboost\n",
    "from sklearn.metrics import roc_auc_score               # 평가지표(문제에 따라)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "# 문제에서 제시\n",
    "X_train = pd.read_csv('~~~')\n",
    "X_test = pd.read_csv('~~~') \n",
    "Y_train = pd.read_csv('~~~')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 전처리\n",
    "# 변수 나누기\n",
    "# 변수 자료타입에 따라서 num과 cat에 나눠넣기\n",
    "num_cols = []       #수치형 변수\n",
    "cat_cols = []       #범주형 변수\n",
    "y_cols = []         #예측대상(종속변수)\n",
    "\n",
    "# tip) 컬럼 리스트 가져오기 (컬럼명 직접 적지 마세요)\n",
    "# X_train.columns 로 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 갯수 확인\n",
    "print(X_train.isnull().sum())\n",
    "print(Y_train.isnull().sum())\n",
    "\n",
    "# variable.info(), describe() 등으로도 확인 가능\n",
    "#결측치가 있을 경우\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy = 'most_frequent')   #최빈값 채우기로 수치형 범주형 모두 가능\n",
    "X_train[cat_cols + num_cols] = imp.fit_transform(X_train[cat_cols + num_cols])\n",
    "X_test[cat_cols + num_cols] = imp.fit_transform(X_test[cat_cols + num_cols])\n",
    "#X_train[['Var1']] = imp.fit_transform(X_train[['Var1']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 모형 구축\n",
    "# - 데이터 분할\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train[cat_cols + num_cols],\n",
    "                                            y_train[y_col].values.ravel(),    # pd.Series -> nd.array\n",
    "                                            test_size=0.3,\n",
    "                                            stratify= y_train[y_col].values.ravel(), # 분류모형, test set과 validation set의 분류별 비율을 고정함\n",
    "                                            random_state=42)   # 재현을 위해서(선택)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cols 데이터 스케일링 \n",
    "sc = StandardScaler()\n",
    "sc.fit(X_tr[num_cols])   # 누수방지를 위해 fit은 X_tr로만 수행(기준을 잡아주기) 후, 나머지에 대해 스케일링하기\n",
    "X_tr[num_cols]   = sc.transform(X_tr[num_cols])\n",
    "y_tr[num_cols]   = sc.transform(y_tr[num_cols])\n",
    "X_test[num_cols] = sc.transform(X_test[num_cols])                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< variable.values.ravel() 설명 >\n",
    "1. values: 이는 pandas 데이터프레임(DataFrame) 또는 시리즈(Series)에서 실제 값들을 추출하는 메소드입니다. 이를 통해 데이터프레임이나 시리즈에 저장된 값들을 NumPy 배열 형태로 반환합니다.\n",
    "2. ravel(): 이는 다차원 배열을 1차원 배열로 평탄화(flatten)하는 함수입니다. 만약 데이터가 이미 1차원 배열이라면 변화 없이 그대로 반환됩니다. 일반적으로 머신러닝에서는 입력 데이터가 1차원 배열 형태로 사용되기 때문에 이러한 평탄화 과정이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링 \n",
    "## num_cols\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_tr[num_cols])   # 누수방지를 위해 fit은 X_tr로만 수행(기준을 잡아주기) 후, 나머지에 대해 스케일링하기\n",
    "X_tr[num_cols]   = sc.transform(X_tr[num_cols])\n",
    "y_tr[num_cols]   = sc.transform(y_tr[num_cols])\n",
    "X_test[num_cols] = sc.transform(X_test[num_cols])\n",
    "\n",
    "\n",
    "## cat_cols\n",
    "X = pd.concat([X_train[cat_cols], X_test[cat_cols]])  \n",
    "\n",
    "for col in cat_cols:     # 라벨인코더는 각 피쳐별로 수행해야 함\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[col])       # 누수 유의\n",
    "    X_tr[col]   = sc.transform(X_tr[col])\n",
    "    y_tr[col]   = sc.transform(y_tr[col])\n",
    "    X_test[col] = sc.transform(X_test[col])\n",
    "\n",
    "    # 변수 클래스 확인방법(not 필수)\n",
    "    print(col)\n",
    "    print(le.classes_, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류모델 학습\n",
    "m1 = RandomForestClassifier()\n",
    "m1.fit(X_tr, y_tr)\n",
    "pred1 = m1.predict_proba(X_val)[:, 1]  #predict_proba 시 출력은 [0일 확률, 1일 확률]로 구성됨 # roc-auc 스코어를 쓰기 때문에, thread-hold에 영향을 받지 않음.\n",
    "\n",
    "m2 = XGBClassifier()\n",
    "m2.fit(X_tr, y_tr)\n",
    "pred2 = m2.predict_proba(X_val)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모형평가\n",
    "# 분류모델 평가\n",
    "score1 = roc_auc_score(y_val, pred1)\n",
    "score2 = roc_auc_score(y_val, pred1)\n",
    "\n",
    "print(score1, score2)   #roc는 점수가 높은 모델을 선정\n",
    "\n",
    "#최종 모델 선정\n",
    "best_model = m1   # m1 or m2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 결과 생성\n",
    "# 분류모델의 경우, 채점 평가 지표에 따라 예측값인지, 예측 확률인지를 결정함\n",
    "\n",
    "# 예측 **확률** 제출  roc_auc_score 인 경우?\n",
    "  # pred = best_model.predict_proba(X_test[cat_cols + num_cols])[:,1]\n",
    "\n",
    "# 예측 **결과** 제출   accuracy, F1 등 confusion matrix 기반 성능평가시\n",
    "  # pred = best_model.predict(X_test[cat_cols + num_cols])[:,1]\n",
    "\n",
    "#결과제출\n",
    "# 답안 제출 참고\n",
    "# 아래 코드는 예시이며 변수명 등 개인별로 변경하여 활용\n",
    "result = pd.DataFrame('pred': pred)\n",
    "result.to_csv(\"result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 모듈 임포트\n",
    "\n",
    "# 공통모듈\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 회귀모델\n",
    "from sklearn.ensemble import RandomForestRegressor   # 회귀모델, 랜덤포레스트\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error  #평가지표 MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "# - 문제에 나온 경로 그대로\n",
    "X_train = pd.read_csv()\n",
    "y_train = pd.read_csv()\n",
    "X_test = pd.read_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 데이터 전처리\n",
    "# 변수 나누기\n",
    "# 변수 자료타입에 따라서 num과 cat에 나눠넣기\n",
    "num_cols = []       #수치형 변수\n",
    "cat_cols = []       #범주형 변수\n",
    "y_cols = []         #예측대상(종속변수)\n",
    "\n",
    "# tip) 컬럼 리스트 가져오기 (컬럼명 직접 적지 마세요)\n",
    "# X_train.columns 로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 갯수 확인\n",
    "print(X_train.isnull().sum())\n",
    "print(Y_train.isnull().sum())\n",
    "\n",
    "# variable.info(), describe() 등으로도 확인 가능\n",
    "#결측치가 있을 경우\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy = 'most_frequent')   #최빈값 채우기로 수치형 범주형 모두 가능\n",
    "X_train[cat_cols + num_cols] = imp.fit_transform(X_train[cat_cols + num_cols])\n",
    "X_test[cat_cols + num_cols] = imp.fit_transform(X_test[cat_cols + num_cols])\n",
    "#X_train[['Var1']] = imp.fit_transform(X_train[['Var1']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 모형 구축\n",
    "# - 데이터 분할\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train[cat_cols + num_cols],     # 독립변수\n",
    "                                            y_train[y_col].values.ravel(),    # 종속변수, pd.Series -> nd.array\n",
    "                                            test_size=0.3,                    # 7:3 분할\n",
    "                                            random_state=42)   # 재현을 위해서\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< variable.values.ravel() 설명 >\n",
    "1. values: 이는 pandas 데이터프레임(DataFrame) 또는 시리즈(Series)에서 실제 값들을 추출하는 메소드입니다. 이를 통해 데이터프레임이나 시리즈에 저장된 값들을 NumPy 배열 형태로 반환합니다.\n",
    "2. ravel(): 이는 다차원 배열을 1차원 배열로 평탄화(flatten)하는 함수입니다. 만약 데이터가 이미 1차원 배열이라면 변화 없이 그대로 반환됩니다. 일반적으로 머신러닝에서는 입력 데이터가 1차원 배열 형태로 사용되기 때문에 이러한 평탄화 과정이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 스케일링 \n",
    "## num_cols\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_tr[num_cols])   # 누수방지를 위해 fit은 X_tr로만 수행(기준을 잡아주기) 후, 나머지에 대해 스케일링하기\n",
    "X_tr[num_cols]   = sc.transform(X_tr[num_cols])\n",
    "y_tr[num_cols]   = sc.transform(y_tr[num_cols])\n",
    "X_test[num_cols] = sc.transform(X_test[num_cols])\n",
    "\n",
    "\n",
    "## cat_cols\n",
    "X = pd.concat([X_train[cat_cols], X_test[cat_cols]])  \n",
    "\n",
    "for col in cat_cols:     # 라벨인코더는 각 피쳐별로 수행해야 함\n",
    "    le = LabelEncoder()\n",
    "    le.fit(X[col])       # 누수 유의\n",
    "    X_tr[col]   = sc.transform(X_tr[col])\n",
    "    y_tr[col]   = sc.transform(y_tr[col])\n",
    "    X_test[col] = sc.transform(X_test[col])\n",
    "\n",
    "    # 변수 클래스 확인방법(not 필수)\n",
    "    print(col)\n",
    "    print(le.classes_, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류모델 학습\n",
    "## 회귀모델에는 proba가 없음.\n",
    "## predict 시 출력은 예측값을 직접 출력\n",
    "m1 = RandomForestRegressor()\n",
    "m1.fit(X_tr, y_tr)\n",
    "pred1 = m1.predict(X_val)[:, 1]  \n",
    "\n",
    "\n",
    "m2 = XGBRegressor()\n",
    "m2.fit(X_tr, y_tr)\n",
    "pred2 = m2.predict(X_val)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 모형평가\n",
    "# 분류모델 평가\n",
    "score1 = mean_squared_error(y_val, pred1)\n",
    "score2 = mean_squared_error(y_val, pred1)\n",
    "\n",
    "print(score1, score2)   # mse는 적을수록 정확한 예측, 점수가 적은 모델을 선정\n",
    "\n",
    "#최종 모델 선정\n",
    "best_model = m1   # m1 or m2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 결과 생성\n",
    "# 분류모델의 경우, 채점 평가 지표에 따라 예측값인지, 예측 확률인지를 결정함\n",
    "\n",
    "# 예측 **확률** 제출  roc_auc_score 인 경우?\n",
    "  # pred = best_model.predict_proba(X_test[cat_cols + num_cols])[:,1]\n",
    "\n",
    "# 예측 **결과** 제출   accuracy, F1 등 confusion matrix 기반 성능평가시\n",
    "  # pred = best_model.predict(X_test[cat_cols + num_cols])[:,1]\n",
    "\n",
    "#결과제출\n",
    "# 답안 제출 참고\n",
    "# 아래 코드는 예시이며 변수명 등 개인별로 변경하여 활용\n",
    "result = pd.DataFrame('pred': pred)\n",
    "result.to_csv(\"result.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
