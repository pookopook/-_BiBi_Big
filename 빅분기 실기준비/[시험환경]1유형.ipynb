{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅분기 1유형 샘플문제\n",
    "[빅분기 시험환경 링크](https://dataq.goorm.io/exam/3/%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B8%B0%EC%82%AC-%EC%8B%A4%EA%B8%B0-%EC%B2%B4%ED%97%98/quiz/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/mtcars.csv\", index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mazda RX4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mazda RX4 Wag</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datsun 710</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet 4 Drive</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hornet Sportabout</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "Mazda RX4          21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "Mazda RX4 Wag      21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "Datsun 710         22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "Hornet 4 Drive     21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "                   carb  \n",
       "Mazda RX4             4  \n",
       "Mazda RX4 Wag         4  \n",
       "Datsun 710            1  \n",
       "Hornet 4 Drive        1  \n",
       "Hornet Sportabout     2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문제1\n",
    " - qsec 컬럼을 Min-Max Scale 로 변환 후 0.5보다 큰 값을 가지는 레코드 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공식으로 풀기  \n",
    " - min-max scaler  \n",
    "$\n",
    "MinMaxScale = \\frac{(value - min)}{(max - min)}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "result = (df['qsec'] - df['qsec'].min() ) / (df['qsec'].max() - df['qsec'].min())\n",
    "print(len(result[result > 0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn 라이브러리로 풀기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 라이브러리 찾기  \n",
    "  일단 sklearn, preprocessing에 있다는걸 알아야하는데.  \n",
    "  생각이 안나거나, 모를수도 있잖아요.  \n",
    "  그럴때는 라이브러리를 하나씩 뒤져봅니다.  \n",
    "  공부한게 생각나기를 바라면서...  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calibration', 'cluster', 'covariance', 'cross_decomposition', 'datasets', 'decomposition', 'dummy', 'ensemble', 'exceptions', 'experimental', 'externals', 'feature_extraction', 'feature_selection', 'gaussian_process', 'inspection', 'isotonic', 'kernel_approximation', 'kernel_ridge', 'linear_model', 'manifold', 'metrics', 'mixture', 'model_selection', 'multiclass', 'multioutput', 'naive_bayes', 'neighbors', 'neural_network', 'pipeline', 'preprocessing', 'random_projection', 'semi_supervised', 'svm', 'tree', 'discriminant_analysis', 'impute', 'compose', 'clone', 'get_config', 'set_config', 'config_context', 'show_versions']\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Binarizer', 'FunctionTransformer', 'KBinsDiscretizer', 'KernelCenterer', 'LabelBinarizer', 'LabelEncoder', 'MultiLabelBinarizer', 'MinMaxScaler', 'MaxAbsScaler', 'QuantileTransformer', 'Normalizer', 'OneHotEncoder', 'OrdinalEncoder', 'PowerTransformer', 'RobustScaler', 'SplineTransformer', 'StandardScaler', 'TargetEncoder', 'add_dummy_feature', 'PolynomialFeatures', 'binarize', 'normalize', 'scale', 'robust_scale', 'maxabs_scale', 'minmax_scale', 'label_binarize', 'quantile_transform', 'power_transform']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "print(sklearn.preprocessing.__all__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform features by scaling each feature to a given range.\n",
      "\n",
      "    This estimator scales and translates each feature individually such\n",
      "    that it is in the given range on the training set, e.g. between\n",
      "    zero and one.\n",
      "\n",
      "    The transformation is given by::\n",
      "\n",
      "        X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      "        X_scaled = X_std * (max - min) + min\n",
      "\n",
      "    where min, max = feature_range.\n",
      "\n",
      "    This transformation is often used as an alternative to zero mean,\n",
      "    unit variance scaling.\n",
      "\n",
      "    `MinMaxScaler` doesn't reduce the effect of outliers, but it linearly\n",
      "    scales them down into a fixed range, where the largest occurring data point\n",
      "    corresponds to the maximum value and the smallest one corresponds to the\n",
      "    minimum value. For an example visualization, refer to :ref:`Compare\n",
      "    MinMaxScaler with other scalers <plot_all_scaling_minmax_scaler_section>`.\n",
      "\n",
      "    Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    feature_range : tuple (min, max), default=(0, 1)\n",
      "        Desired range of transformed data.\n",
      "\n",
      "    copy : bool, default=True\n",
      "        Set to False to perform inplace row normalization and avoid a\n",
      "        copy (if the input is already a numpy array).\n",
      "\n",
      "    clip : bool, default=False\n",
      "        Set to True to clip transformed values of held-out data to\n",
      "        provided `feature range`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    min_ : ndarray of shape (n_features,)\n",
      "        Per feature adjustment for minimum. Equivalent to\n",
      "        ``min - X.min(axis=0) * self.scale_``\n",
      "\n",
      "    scale_ : ndarray of shape (n_features,)\n",
      "        Per feature relative scaling of the data. Equivalent to\n",
      "        ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *scale_* attribute.\n",
      "\n",
      "    data_min_ : ndarray of shape (n_features,)\n",
      "        Per feature minimum seen in the data\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *data_min_*\n",
      "\n",
      "    data_max_ : ndarray of shape (n_features,)\n",
      "        Per feature maximum seen in the data\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *data_max_*\n",
      "\n",
      "    data_range_ : ndarray of shape (n_features,)\n",
      "        Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *data_range_*\n",
      "\n",
      "    n_features_in_ : int\n",
      "        Number of features seen during :term:`fit`.\n",
      "\n",
      "        .. versionadded:: 0.24\n",
      "\n",
      "    n_samples_seen_ : int\n",
      "        The number of samples processed by the estimator.\n",
      "        It will be reset on new calls to fit, but increments across\n",
      "        ``partial_fit`` calls.\n",
      "\n",
      "    feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "        Names of features seen during :term:`fit`. Defined only when `X`\n",
      "        has feature names that are all strings.\n",
      "\n",
      "        .. versionadded:: 1.0\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    minmax_scale : Equivalent function without the estimator API.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      "    transform.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.preprocessing import MinMaxScaler\n",
      "    >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      "    >>> scaler = MinMaxScaler()\n",
      "    >>> print(scaler.fit(data))\n",
      "    MinMaxScaler()\n",
      "    >>> print(scaler.data_max_)\n",
      "    [ 1. 18.]\n",
      "    >>> print(scaler.transform(data))\n",
      "    [[0.   0.  ]\n",
      "     [0.25 0.25]\n",
      "     [0.5  0.5 ]\n",
      "     [1.   1.  ]]\n",
      "    >>> print(scaler.transform([[2, 2]]))\n",
      "    [[1.5 0. ]]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "print(MinMaxScaler.__doc__)\n",
    "# 도움말까지 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 개\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data = df[['qsec']]  ## 괄호 두번\n",
    "\n",
    "scaler.fit(data)\n",
    "result = data[scaler.transform(data) > 0.5]\n",
    "print(len(result),\"개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 개\n"
     ]
    }
   ],
   "source": [
    "# fit_transform도 가능\n",
    "result = data[scaler.fit_transform(data) > 0.5]\n",
    "print(len(result),\"개\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
